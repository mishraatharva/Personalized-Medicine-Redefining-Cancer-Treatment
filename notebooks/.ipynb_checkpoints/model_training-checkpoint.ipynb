{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix,normalized_mutual_info_score\n",
    "from sklearn.metrics._classification import accuracy_score, log_loss\n",
    "from sklearn.linear_model import SGDClassifier,LogisticRegression\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.svm import SVC \n",
    "# from sklearn.cross_validation import StratifiedClassifierCV\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import math\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "from collections import Counter,defaultdict\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.read_csv(r\"U:\\nlp_project\\Personalized-Medicine-Redefining-Cancer-Treatment\\artifacts\\data\\final_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. train-test-split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = final_data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.Gene = final_data.Gene.str.replace('\\s+', '_')\n",
    "final_data.Variation = final_data.Gene.str.replace('\\s+', '_')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(final_data, y_true, random_state=42, test_size=0.20)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=45, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of datapoints in train dataset: {X_train.shape[0]}\")\n",
    "print(f\"Number of datapoints in test dataset: {X_test.shape[0]}\")\n",
    "print(f\"Number of datapoints in validation dataset: {X_val.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Distribution of class in train, test and split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_class_distibution = y_train.value_counts()\n",
    "test_class_distribution = y_test.value_counts()\n",
    "validation_class_distribution = y_val.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_class_distibution.plot(kind='bar')\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"train_class_distibution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So we have multi-class classification problem with highly imbalanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_class_distribution.plot(kind=\"bar\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"test_class_distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train and test have almost similar distribution on class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_class_distribution.plot(kind=\"bar\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"validation_class_distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is Geni and Variation feature are stable accross all the Train, Test and Validation data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(X_train[\"Gene\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_coverage = len(set(X_test[\"Gene\"]) & set(X_train[\"Gene\"]))\n",
    "validation_coverage = len(set(X_val[\"Gene\"]) & set(X_train[\"Gene\"]))\n",
    "\n",
    "print(f\"in test data {test_coverage} out of {X_test.shape[0]}\")\n",
    "print(f\"in test data {validation_coverage} out of {X_val.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_coverage = len(set(X_test[\"Variation\"]) & set(X_train[\"Variation\"]))\n",
    "validation_coverage = len(set(X_val[\"Variation\"]) & set(X_train[\"Variation\"]))\n",
    "\n",
    "print(f\"in test data {test_coverage} out of {X_test.shape[0]}\")\n",
    "print(f\"in test data {validation_coverage} out of {X_val.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = []\n",
    "for txt in X_train[\"Text\"]:\n",
    "    unique_word = list(set(txt.split()))\n",
    "    unique_words.extend(unique_word) \n",
    "\n",
    "print(f\"total unique words {len(unique_words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = pd.Series(unique_words)\n",
    "unique_words_value_counts = unique_words.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words_value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = sum(unique_words_value_counts.values);\n",
    "h = unique_words_value_counts.values/s;\n",
    "\n",
    "plt.plot(h, label=\"Histogram of unique words\")\n",
    "plt.xlabel(\"Index of words\")\n",
    "plt.ylabel(\"Number of occurences\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.cumsum(h)\n",
    "plt.plot(c, label=\"Cumulative distribution of genes\")\n",
    "plt.grid(axis=\"both\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Prediction Using Random Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrics(y_test, y_pred):\n",
    "    label = [1,2,3,4,5,6,7,8,9]\n",
    "    C = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    A = (((C.T) / C.sum(axis=1)).T)\n",
    "\n",
    "    B = (C/C.sum(axis=0))\n",
    "\n",
    "    print(\"-\"*80, \"Confusion Matrix\", \"-\"*20)\n",
    "    plt.figure(figsize=(20,7))\n",
    "    sns.heatmap(C, annot=True, fmt=\".3f\", xticklabels=label,yticklabels=label)\n",
    "    plt.xlabel(\"Predicted Values\")\n",
    "    plt.ylabel(\"Original Values\")\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"-\"*80, \"Precision Matrix (Column sum=1)\", \"-\"*20)\n",
    "    plt.figure(figsize=(20,7))\n",
    "    sns.heatmap(B, annot=True, fmt=\".3f\", xticklabels=label,yticklabels=label)\n",
    "    plt.xlabel(\"Predicted Values\")\n",
    "    plt.ylabel(\"Original Values\")\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"-\"*80, \"Recall Matrix (Column sum=1)\", \"-\"*20)\n",
    "    plt.figure(figsize=(20,7))\n",
    "    sns.heatmap(A, annot=True, fmt=\".3f\", xticklabels=label,yticklabels=label)\n",
    "    plt.xlabel(\"Predicted Values\")\n",
    "    plt.ylabel(\"Original Values\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics._classification import log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1: validation-set-error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_data_len = X_val.shape[0]\n",
    "cv_predicted_y = np.zeros((cv_data_len,9)) # cv_predicted_y will have 531-col, 9-rows\n",
    "for i in range(cv_data_len):\n",
    "    random_probability = np.random.rand(1,9)\n",
    "    cv_predicted_y[i] = random_probability / random_probability.sum()\n",
    "print(\"log-loss on cross validation data using Random Model\", log_loss(y_val,cv_predicted_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Test-Set-Error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_len = X_test.shape[0]\n",
    "\n",
    "test_predicted_y = np.zeros((test_data_len,9)) # cv_predicted_y will have 531-col, 9-rows\n",
    "for i in range(test_data_len):\n",
    "    random_probability = np.random.rand(1,9)\n",
    "    test_predicted_y[i] = random_probability / random_probability.sum()\n",
    "print(\"log-loss on test data using Random Model\", log_loss(y_test,test_predicted_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y = np.argmax(test_predicted_y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrics(y_test, predicted_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Is Geni and variation feature are important for predicting classes: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1: Deciding is Gine model is good at predicting class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer_gine = CountVectorizer()\n",
    "\n",
    "gene_x_train_ohe = count_vectorizer_gine.fit_transform(X_train[\"Gene\"])\n",
    "gene_x_test_ohe = count_vectorizer_gine.transform(X_test[\"Gene\"])\n",
    "gene_x_val_ohe = count_vectorizer_gine.transform(X_val[\"Gene\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [10 ** x for x in range(-5,1)]\n",
    "\n",
    "cv_log_error_array = []\n",
    "\n",
    "for i in alpha:\n",
    "    clf = SGDClassifier(alpha=i,penalty=\"l2\", loss=\"log_loss\",random_state=42)\n",
    "    clf.fit(gene_x_train_ohe, y_train)\n",
    "    sig_clf = CalibratedClassifierCV(clf,method=\"sigmoid\")\n",
    "    sig_clf.fit(gene_x_train_ohe, y_train)\n",
    "    pred_y = sig_clf.predict_proba(gene_x_val_ohe)\n",
    "    cv_log_error_array.append(log_loss(y_val,pred_y,labels=clf.classes_))\n",
    "\n",
    "    print(f\"for value of alpha {i},The log_loss is: {log_loss(y_val,pred_y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Gene feature on best found alpha value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_alpha= np.argmin(cv_log_error_array)\n",
    "clf = SGDClassifier(alpha=alpha[best_alpha],penalty=\"l2\", loss=\"log_loss\",random_state=42)\n",
    "clf.fit(gene_x_train_ohe, y_train)\n",
    "sig_clf = CalibratedClassifierCV(clf,method=\"sigmoid\")\n",
    "sig_clf.fit(gene_x_train_ohe, y_train)\n",
    "\n",
    "\n",
    "pred_y = sig_clf.predict_proba(gene_x_train_ohe)\n",
    "print(\"log loss for train: \", log_loss(y_train,pred_y))\n",
    "pred_y = sig_clf.predict_proba(gene_x_test_ohe)\n",
    "print(\"log loss for test: \", log_loss(y_test,pred_y))\n",
    "pred_y = sig_clf.predict_proba(gene_x_val_ohe)\n",
    "print(\"log loss for validation: \", log_loss(y_val,pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2: Deciding is Variation feature is good at predicting class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer_variation = CountVectorizer()\n",
    "\n",
    "Variation_x_train_ohe = count_vectorizer_variation.fit_transform(X_train[\"Variation\"])\n",
    "Variation_x_test_ohe = count_vectorizer_variation.transform(X_test[\"Variation\"])\n",
    "Variation_x_val_ohe = count_vectorizer_variation.transform(X_val[\"Variation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Variation feature on best found alpha value:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [10 ** x for x in range(-5,1)]\n",
    "\n",
    "cv_log_error_array = []\n",
    "\n",
    "for i in alpha:\n",
    "    clf = SGDClassifier(alpha=i,penalty=\"l2\", loss=\"log_loss\",random_state=42)\n",
    "    clf.fit(Variation_x_train_ohe, y_train)\n",
    "    sig_clf = CalibratedClassifierCV(clf,method=\"sigmoid\")\n",
    "    sig_clf.fit(Variation_x_train_ohe, y_train)\n",
    "    pred_y = sig_clf.predict_proba(Variation_x_val_ohe)\n",
    "    cv_log_error_array.append(log_loss(y_val,pred_y,labels=clf.classes_))\n",
    "\n",
    "    print(f\"for value of alpha {i},The log_loss is: {log_loss(y_val,pred_y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_alpha= np.argmin(cv_log_error_array)\n",
    "clf = SGDClassifier(alpha=alpha[best_alpha],penalty=\"l2\", loss=\"log_loss\",random_state=42)\n",
    "clf.fit(Variation_x_train_ohe, y_train)\n",
    "sig_clf = CalibratedClassifierCV(clf,method=\"sigmoid\")\n",
    "sig_clf.fit(Variation_x_train_ohe, y_train)\n",
    "\n",
    "\n",
    "pred_y = sig_clf.predict_proba(Variation_x_train_ohe)\n",
    "print(\"log loss for train: \", log_loss(y_train,pred_y))\n",
    "pred_y = sig_clf.predict_proba(Variation_x_test_ohe)\n",
    "print(\"log loss for test: \", log_loss(y_test,pred_y))\n",
    "pred_y = sig_clf.predict_proba(Variation_x_val_ohe)\n",
    "print(\"log loss for validation: \", log_loss(y_val,pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conclusion_df = {\n",
    "    \"cv_loss\": [1.14,1.16,2.49],\n",
    "    \"test_loss\": [1.16,1.14,2.48],\n",
    "}\n",
    "\n",
    "pd.DataFrame(conclusion_df, index=[\"gene\", \"variation\", \"random model\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### conclusion:\n",
    "- As we can see both are fetures are important,  so keep both feature for predicting class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3: Deciding is test feature is good at predicting class:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How many unique values are present in train data.\n",
    "- how are text frequency distributed?\n",
    "- How to featurize text field?\n",
    "- Is text feature usefull for predicting y?\n",
    "- Is the text feature stable across Train,test and validation data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorizer = CountVectorizer(min_df=3) # min_df: take those words only which occured atleast 3 times\n",
    "train_txt_ohe = text_vectorizer.fit_transform(X_train[\"Text\"])\n",
    "train_text_features = text_vectorizer.get_feature_names_out()\n",
    "\n",
    "train_text_feature_counts = train_txt_ohe.sum(axis=0).A1\n",
    "\n",
    "text_feature_dict = dict(zip(list(train_text_features), train_text_feature_counts))\n",
    "print(f\"total_number of unique words in train data: {len(train_text_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/16202486\n",
    "\n",
    "# convert each row values such that they sum sum to 1, i.e normalize response coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing every feature\n",
    "train_txt_ohe = normalize(train_txt_ohe)\n",
    "test_text_ohe = normalize(text_vectorizer.transform(X_test[\"Text\"]))\n",
    "val_text_ohe = normalize(text_vectorizer.transform(X_val[\"Text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://stackoverflow.com/a/2258273/4084039\n",
    "# sorted_text_feature_dict = dict(sorted(text_feature_dict.items(), key=lambda x:x[1]))\n",
    "# sorted_text_occur = np.array(list(sorted_text_feature_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(Counter(sorted_text_occur))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 5306 word occur 3 times\n",
    "- 4037 words occur 4 times\n",
    "-\n",
    "-\n",
    "-\n",
    "- and so on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training text feature on best found alpha value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [10 ** x for x in range(-5,1)]\n",
    "\n",
    "cv_log_error_array = []\n",
    "\n",
    "for i in alpha:\n",
    "    clf = SGDClassifier(alpha=i,penalty=\"l2\", loss=\"log_loss\",random_state=42)\n",
    "    clf.fit(train_txt_ohe, y_train)\n",
    "    sig_clf = CalibratedClassifierCV(clf,method=\"sigmoid\")\n",
    "    sig_clf.fit(train_txt_ohe, y_train)\n",
    "    pred_y = sig_clf.predict_proba(val_text_ohe)\n",
    "    cv_log_error_array.append(log_loss(y_val,pred_y,labels=clf.classes_))\n",
    "\n",
    "    print(f\"for value of alpha {i},The log_loss is: {log_loss(y_val,pred_y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_alpha= np.argmin(cv_log_error_array)\n",
    "clf = SGDClassifier(alpha=alpha[best_alpha],penalty=\"l2\", loss=\"log_loss\",random_state=42)\n",
    "clf.fit(train_txt_ohe, y_train)\n",
    "sig_clf = CalibratedClassifierCV(clf,method=\"sigmoid\")\n",
    "sig_clf.fit(train_txt_ohe, y_train)\n",
    "\n",
    "\n",
    "pred_y = sig_clf.predict_proba(train_txt_ohe)\n",
    "print(\"log loss for train: \", log_loss(y_train,pred_y))\n",
    "pred_y = sig_clf.predict_proba(test_text_ohe)\n",
    "print(\"log loss for test: \", log_loss(y_test,pred_y))\n",
    "pred_y = sig_clf.predict_proba(val_text_ohe)\n",
    "print(\"log loss for validation: \", log_loss(y_val,pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conclusion_df = {\n",
    "    \"cv_loss\": [1.14,1.16,1.34,2.49],\n",
    "    \"test_loss\": [1.16,1.14,1.32,2.48],\n",
    "}\n",
    "\n",
    "pd.DataFrame(conclusion_df, index=[\"gene\", \"variation\", \"text\",\"random model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intersaction_text(df):\n",
    "    df_text_vec = CountVectorizer(max_df=3)\n",
    "    df_text_fea = df_text_vec.fit_transform(df[\"Text\"])\n",
    "    df_text_feature =df_text_vec.get_feature_names_out()\n",
    "    df_text_fea_counts = df_text_fea.sum(axis=0).A1\n",
    "    df_text_fea_dict = dict(zip(list(df_text_feature), df_text_fea_counts))\n",
    "    len1 = len(set(df_text_feature))\n",
    "    len2 = len(set(train_text_features) & set(df_text_feature))\n",
    "    return len1,len2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len1, len2 = get_intersaction_text(X_test)\n",
    "print(np.round((len1/len2)*100,3), \"% of word of test data appeared in training data.\")\n",
    "len1, len2 = get_intersaction_text(X_val)\n",
    "print(np.round((len2/len1)*100,3), \"% of word of validation data appeared in training data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Machine Learning Models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(\"int\")\n",
    "y_test = y_test.astype(\"int\")\n",
    "y_val = y_val.astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_plot_confusion_matrix(train_x, train_y, x_test, y_test, clf):\n",
    "    clf.fit(train_x,train_y)\n",
    "    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "    sig_clf.fit(train_x, train_y)\n",
    "    y_pred = sig_clf.predict(x_test)\n",
    "\n",
    "\n",
    "    print(f\"Log_loss {log_loss(y_test, sig_clf.predict_proba(x_test))}\")\n",
    "    print(f\"number of missclassified points: {np.count_nonzero((y_pred-x_test))}\")\n",
    "\n",
    "    plot_confusion_matrics(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_log_loss(X_train, y_train, X_test, y_test, clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
    "    sig_clf_probs = sig_clf.predict_proba(X_test)\n",
    "    return log_loss(y_test, sig_clf_probs, eps=1e-15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For Naive Bias Classifier\n",
    "# def important_feature_names(indices, text, gene, var, no_features):\n",
    "#     gene_count_vectorizer = CountVectorizer()\n",
    "#     variance_count_vectorizer = CountVectorizer()\n",
    "#     text_count_vectorizer = CountVectorizer(min_df=3)\n",
    "\n",
    "#     gene_vec = gene_count_vectorizer.fit(X_train[\"Gene\"])\n",
    "#     variance_vec = variance_count_vectorizer.fit(X_train[\"Variance\"])    \n",
    "#     text_vec = text_count_vectorizer.fit(X_train[\"Text\"])\n",
    "\n",
    "#     fea1_len = len(gene_vec.get_feature_names_out())\n",
    "#     fea2_len = len(variance_vec.get_feature_names_out())\n",
    "\n",
    "#     word_present = 0\n",
    "#     for i,v in enumerate(indices):\n",
    "#         if (v < fea1_len):\n",
    "#             word = gene_vec.get_feature_names_out()[v]\n",
    "#             yes_no = True if word == gene else False\n",
    "#             if yes_no:\n",
    "#                 word_present += 1\n",
    "#                 print(i, \"Gene feature [{}] present in test data point [{}]\")\n",
    "        \n",
    "#         elif (v < fea1_len + fea2_len):\n",
    "#             word = variance_vec.get_feature_names_out()[v-(fea1_len)]\n",
    "#             yes_no = True if word==var else False\n",
    "#             if yes_no:\n",
    "#                 word_present += 1\n",
    "#                 print(i, \"Variation feature [{}] present in test data point [{}]\")\n",
    "\n",
    "#         else:\n",
    "#             word = text_vec.get_feature_names_out()[v]\n",
    "#             yes_no = True if word == gene else False\n",
    "#             if yes_no:\n",
    "#                 word_present += 1\n",
    "#                 print(i, \"text feature [{}] present in test data point [{}]\")\n",
    "    \n",
    "#     print(\"Out of the top \", no_features, \"features\", word_present, \"are present\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepairing train-test-validation data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. CountVectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = hstack((gene_x_train_ohe,Variation_x_train_ohe))\n",
    "train_df_ohe = hstack((train_df, train_txt_ohe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = hstack((gene_x_test_ohe,Variation_x_test_ohe))\n",
    "test_df_ohe = hstack((test_df, test_text_ohe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df = hstack((gene_x_val_ohe,Variation_x_val_ohe))\n",
    "validation_df_ohe = hstack((validation_df, val_text_ohe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"One hot encoding features :\")\n",
    "\n",
    "print(\"(Numner of data points * Number of features) in train data = \", train_df_ohe.shape)\n",
    "print(\"(Numner of data points * Number of features) in test data = \", test_df_ohe.shape)\n",
    "print(\"(Numner of data points * Number of features) in validation data = \", validation_df_ohe.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. ResponseCoding :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from response_encoding import CategoricalMeanValueReplacement,TextMeanValueReplacement\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_cmvr = CategoricalMeanValueReplacement()\n",
    "variation_cmvr = CategoricalMeanValueReplacement()\n",
    "tmvr = TextMeanValueReplacement(X_train, \"Text\", \"Class\", 1, 9, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_cmvr.fit(1,X_train,\"Gene\",\"Class\")\n",
    "variation_cmvr.fit(1,X_train,\"Variation\",\"Class\")\n",
    "tmvr.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gene_response_encoding = gene_cmvr.transform(X_train)\n",
    "test_gene_response_encoding = gene_cmvr.transform(X_test)\n",
    "validation_gene_response_encoding = gene_cmvr.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_variation_response_encoding = variation_cmvr.transform(X_train)\n",
    "test_variation_response_encoding = variation_cmvr.transform(X_test)\n",
    "validation_variation_response_encoding = variation_cmvr.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_response_encoding = tmvr.transform(X_train,\"Class\")\n",
    "test_text_response_encoding = tmvr.transform(X_test,\"Class\")\n",
    "validation_text_response_encoding = tmvr.transform(X_val,\"Class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_re = np.hstack((train_gene_response_encoding,train_variation_response_encoding))\n",
    "train_df_re = np.hstack((train_df_re,train_text_response_encoding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_re = np.hstack((test_gene_response_encoding,test_variation_response_encoding))\n",
    "test_df_re = np.hstack((test_df_re,test_text_response_encoding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df_re = np.hstack((validation_gene_response_encoding,validation_variation_response_encoding))\n",
    "validation_df_re = np.hstack((validation_df_re,validation_text_response_encoding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"One hot encoding features :\")\n",
    "\n",
    "print(\"(Numner of data points * Number of features) in train data = \", train_df_re.shape)\n",
    "print(\"(Numner of data points * Number of features) in test data = \", test_df_re.shape)\n",
    "print(\"(Numner of data points * Number of features) in validation data = \", validation_df_re.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [0.00001,0.0001,0.001,0.1,1,10,100,1000]\n",
    "cv_log_error_array = []\n",
    "for i in alpha:\n",
    "    print(f\"for alpha {i}\")\n",
    "    clf = MultinomialNB(alpha=i)\n",
    "    clf.fit(train_df_ohe, y_train)\n",
    "    sig_clf = CalibratedClassifierCV(clf,method=\"sigmoid\")\n",
    "    sig_clf.fit(train_df_ohe, y_train)\n",
    "    sig_clf_prob = sig_clf.predict_proba(validation_df_ohe)\n",
    "    print(len(y_val), len(sig_clf_prob))\n",
    "    cv_log_error_array.append(log_loss(y_val, sig_clf_prob, labels=clf.classes_))\n",
    "    print(\"log loss :\", log_loss(y_val, sig_clf_prob))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.log10(alpha), cv_log_error_array, c=\"g\")\n",
    "for i, txt in enumerate(np.round(cv_log_error_array,3)):\n",
    "    ax.annotate((alpha[i],str(txt)), (np.log10(alpha[i]), cv_log_error_array[i]))\n",
    "plt.grid()\n",
    "plt.xticks(np.log10(alpha))\n",
    "plt.title(\"Cross Validation Error for each alpha\")\n",
    "plt.xlabel(\"Alpha i's\")\n",
    "plt.ylabel(\"Error measure\")\n",
    "plt.legend()\n",
    "\n",
    "best_alpha = np.argmin(cv_log_error_array)\n",
    "clf = MultinomialNB(alpha=alpha[best_alpha])\n",
    "clf.fit(train_df_ohe, y_train)\n",
    "sig_clf = CalibratedClassifierCV(clf,method=\"sigmoid\")\n",
    "sig_clf.fit(train_df_ohe, y_train)\n",
    "\n",
    "\n",
    "sig_clf_prob = sig_clf.predict_proba(train_df_ohe)\n",
    "print(\"for best alpha \", alpha[best_alpha], \"The train log loss is: \",log_loss(y_train, sig_clf_prob, labels=clf.classes_))\n",
    "\n",
    "sig_clf_prob = sig_clf.predict_proba(validation_df_ohe)\n",
    "print(\"for best alpha \", alpha[best_alpha], \"The validation log loss is: \",log_loss(y_val, sig_clf_prob, labels=clf.classes_))\n",
    "\n",
    "sig_clf_prob = sig_clf.predict_proba(test_df_ohe)\n",
    "print(\"for best alpha \", alpha[best_alpha], \"The test log loss is: \",log_loss(y_test, sig_clf_prob, labels=clf.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from confusion matrix: of all the points get predicted as class-1 among them 47% are actually belongs to class-1\n",
    "# from precision matrix: of all the points get predicted as class-1 among them 30% are actually belongs to class-4\n",
    "# from recall matrix: of all the points belongs class-6 among them 13% are predicted as class-1, 39% predicted as class-6 it self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_clf_prob = sig_clf.predict(validation_df_ohe)\n",
    "plot_confusion_matrics(y_val,sig_clf_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 K-Nearest Neighbour Classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neighbors = [2,5,6,7,8,10,12]\n",
    "neighbors = [5,11,15,21,31,41,51,99]\n",
    "\n",
    "cv_log_error_array = []\n",
    "for k in neighbors:\n",
    "    print(f\"for neighbor {k}\")\n",
    "    clf = KNeighborsClassifier(n_neighbors=k)\n",
    "    clf.fit(train_df_re, y_train)\n",
    "    sig_clf = CalibratedClassifierCV(clf,method=\"sigmoid\")\n",
    "    sig_clf.fit(train_df_re, y_train)\n",
    "    sig_clf_prob = sig_clf.predict_proba(validation_df_re)\n",
    "    cv_log_error_array.append(log_loss(y_val, sig_clf_prob, labels=clf.classes_))\n",
    "    print(\"log loss :\", log_loss(y_val, sig_clf_prob))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(neighbors, cv_log_error_array, c=\"g\")\n",
    "for i, txt in enumerate(np.round(cv_log_error_array,3)):\n",
    "    ax.annotate((neighbors[i],str(txt)), (neighbors[i], cv_log_error_array[i]))\n",
    "plt.grid()\n",
    "plt.xticks(np.log10(neighbors))\n",
    "\n",
    "\n",
    "plt.title(\"Cross Validation Error for each k\")\n",
    "plt.xlabel(\"neighbors i's\")\n",
    "plt.ylabel(\"Error measure\")\n",
    "plt.legend()\n",
    "\n",
    "best_k = np.argmin(cv_log_error_array)\n",
    "clf = KNeighborsClassifier(n_neighbors=neighbors[best_alpha])\n",
    "clf.fit(train_df_re, y_train)\n",
    "sig_clf = CalibratedClassifierCV(clf,method=\"sigmoid\")\n",
    "sig_clf.fit(train_df_re, y_train)\n",
    "\n",
    "\n",
    "sig_clf_prob = sig_clf.predict_proba(train_df_re)\n",
    "print(\"for best k :\", neighbors[best_k], \"The train log loss is: \",log_loss(y_train, sig_clf_prob, labels=clf.classes_))\n",
    "\n",
    "sig_clf_prob = sig_clf.predict_proba(validation_df_re)\n",
    "print(\"for best k :\", neighbors[best_k], \"The validation log loss is: \",log_loss(y_val, sig_clf_prob, labels=clf.classes_))\n",
    "\n",
    "sig_clf_prob = sig_clf.predict_proba(test_df_re)\n",
    "print(\"for best k :\", neighbors[best_k], \"The test log loss is: \",log_loss(y_test, sig_clf_prob, labels=clf.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_clf_prob = sig_clf.predict(validation_df_re)\n",
    "plot_confusion_matrics(y_val,sig_clf_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(8,6))\n",
    "# for i in range(1,10):\n",
    "#     probabilities = sig_clf.predict_proba(np.array(train_df_re))[:,1]\n",
    "#     prob_true, prob_pred = calibration_curve(y_train==i, probabilities, n_bins=15)\n",
    "#     plt.plot(prob_pred,prob_true,label=f\"class-{i}\")\n",
    "#     plt.plot([0,1],[1,0], linestyle=\"--\", color=\"gray\", label=\"idel_calibration\")\n",
    "#     plt.xlabel(\"mean predicted probability\")\n",
    "#     plt.ylabel(\"fraction of positives\")\n",
    "#     plt.legend()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 LogisticRegression + CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [0.00001,0.0001,0.001,0.1,1,10,100,1000]\n",
    "cv_log_error_array = []\n",
    "for i in alpha:\n",
    "    print(f\"for alpha {i}\")\n",
    "    clf = LogisticRegression(C=i, class_weight=\"balanced\",multi_class=\"ovr\")\n",
    "    clf.fit(np.array(train_df_re), y_train)\n",
    "    sig_clf = CalibratedClassifierCV(clf,method=\"sigmoid\")\n",
    "    sig_clf.fit(np.array(train_df_re), y_train)\n",
    "    sig_clf_prob = sig_clf.predict_proba(np.array(validation_df_re))\n",
    "    print(len(y_val), len(sig_clf_prob))\n",
    "    cv_log_error_array.append(log_loss(y_val, sig_clf_prob, labels=clf.classes_))\n",
    "    print(\"log loss :\", log_loss(y_val, sig_clf_prob))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.log10(alpha), cv_log_error_array, c=\"g\")\n",
    "for i, txt in enumerate(np.round(cv_log_error_array,3)):\n",
    "    ax.annotate((alpha[i],str(txt)), (np.log10(alpha[i]), cv_log_error_array[i]))\n",
    "plt.grid()\n",
    "plt.xticks(np.log10(alpha))\n",
    "plt.title(\"Cross Validation Error for each alpha\")\n",
    "plt.xlabel(\"Alpha i's\")\n",
    "plt.ylabel(\"Error measure\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "best_alpha = np.argmin(cv_log_error_array)\n",
    "clf = MultinomialNB(alpha=alpha[best_alpha])\n",
    "clf.fit(np.array(train_df_re), y_train)\n",
    "sig_clf = CalibratedClassifierCV(clf,method=\"sigmoid\")\n",
    "sig_clf.fit(np.array(train_df_re), y_train)\n",
    "\n",
    "\n",
    "sig_clf_prob = sig_clf.predict_proba(np.array(train_df_re))\n",
    "print(\"for best alpha \", alpha[best_alpha], \"The train log loss is: \",log_loss(y_train, sig_clf_prob, labels=clf.classes_))\n",
    "\n",
    "sig_clf_prob = sig_clf.predict_proba(np.array(validation_df_re))\n",
    "print(\"for best alpha \", alpha[best_alpha], \"The validation log loss is: \",log_loss(y_val, sig_clf_prob, labels=clf.classes_))\n",
    "\n",
    "sig_clf_prob = sig_clf.predict_proba(np.array(test_df_re))\n",
    "print(\"for best alpha \", alpha[best_alpha], \"The test log loss is: \",log_loss(y_test, sig_clf_prob, labels=clf.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Deep Learning Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1: Prepairing Data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.max_memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_sm --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spacy.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spacy.util.get_installed_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = X_train[\"Text\"].tolist()\n",
    "test_text = X_test[\"Text\"].tolist() \n",
    "validation_text = X_val[\"Text\"].tolist()\n",
    "\n",
    "def get_tokenized_text(texts):\n",
    "    tokenized_text = []\n",
    "    for text in texts:\n",
    "        tokenized_text.append(nlp(text))  # Assuming nlp is a spaCy tokenizer\n",
    "    return tokenized_text\n",
    "\n",
    "def create_vocabulary(tokenized_text):\n",
    "    unique_word = set(str(word) for sublist in tokenized_text for word in sublist)  # Convert tokens to strings\n",
    "    vocab = {word: index for index, word in enumerate(unique_word, start=2)}\n",
    "    vocab[\"<pad>\"] = 0  # Padding token\n",
    "    vocab[\"<unk>\"] = 1  # Unknown token\n",
    "    return vocab\n",
    "\n",
    "def text_to_numerical_representation(vocab, tokenized_text):\n",
    "    normalized_data = [[vocab.get(str(word), vocab[\"<unk>\"]) for word in sentence] for sentence in tokenized_text]\n",
    "    return normalized_data\n",
    "\n",
    "tokenized_text_train = get_tokenized_text(train_text)\n",
    "tokenized_text_test = get_tokenized_text(test_text)\n",
    "tokenized_text_validation = get_tokenized_text(validation_text)\n",
    "\n",
    "vocab = create_vocabulary(tokenized_text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_numerical_representation_train = text_to_numerical_representation(vocab, tokenized_text_train)\n",
    "text_to_numerical_representation_test = text_to_numerical_representation(vocab, tokenized_text_test)\n",
    "text_to_numerical_representation_val = text_to_numerical_representation(vocab, tokenized_text_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_numerical_representation_train = [torch.tensor(txt) for txt in text_to_numerical_representation_train]\n",
    "text_to_numerical_representation_test = [torch.tensor(txt) for txt in text_to_numerical_representation_test]\n",
    "text_to_numerical_representation_val = [torch.tensor(txt) for txt in text_to_numerical_representation_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.memory_allocated())\n",
    "print(torch.cuda.max_memory_allocated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "# del train_data, test_data, val_data  # Delete variables if they exist\n",
    "gc.collect()  # Python garbage collection\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_cat(categories, encoder):\n",
    "    print(\"encoding\")\n",
    "    return torch.tensor([encoder.transform([cat])[0] if cat in encoder.classes_ else -1 for cat in categories])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_train = X_train[\"Gene\"].tolist()\n",
    "variation_train = X_train[\"Variation\"].tolist()\n",
    "\n",
    "gene_test = X_test[\"Gene\"].tolist()\n",
    "variation_test = X_test[\"Variation\"].tolist()\n",
    "\n",
    "gene_val = X_val[\"Gene\"].tolist()\n",
    "variation_val = X_val[\"Variation\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- .fit() on train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_gene = LabelEncoder()\n",
    "encoder_variation = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_target = LabelEncoder()\n",
    "y_train = encoder_target.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = encode_cat(y_test, encoder_target)\n",
    "y_val = encode_cat(y_val,encoder_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_train_encoded = encoder_gene.fit_transform(gene_train)\n",
    "variation_train_encoded = encoder_variation.fit_transform(variation_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_test_encoded = encode_cat(gene_test,encoder_gene)\n",
    "variation_test_encoded = encode_cat(variation_test,encoder_variation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_val_encoded = encode_cat(gene_val,encoder_gene)\n",
    "variation_val_encoded = encode_cat(variation_val,encoder_variation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- after pddding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_numerical_representation_train = pad_sequence(sequences=text_to_numerical_representation_train,batch_first=True,padding_value=True)\n",
    "text_to_numerical_representation_test = pad_sequence(sequences=text_to_numerical_representation_test,batch_first=True,padding_value=True)\n",
    "text_to_numerical_representation_val = pad_sequence(sequences=text_to_numerical_representation_val,batch_first=True,padding_value=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "# del train_data, test_data, val_data  # Delete variables if they exist\n",
    "gc.collect()  # Python garbage collection\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.memory_allocated())\n",
    "print(torch.cuda.max_memory_allocated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.1 Model-LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### loading_data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Parameters\n",
    "vocab_size = len(vocab.keys())\n",
    "embed_dim = int(vocab_size ** 0.25)\n",
    "hidden_dim = 128\n",
    "num_classes = 9\n",
    "gene_size = len(gene_train_encoded)\n",
    "variance_size = len(variation_train_encoded)\n",
    "gene_emb_dim = 5\n",
    "variance_emb_dim = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class MultiClassLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_classes, gene_size, variance_size, gene_emb_dim, variance_emb_dim):\n",
    "        super(MultiClassLSTM, self).__init__()\n",
    "\n",
    "        # Text feature embedding + LSTM\n",
    "        self.text_embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(input_size=embed_dim, hidden_size=hidden_dim, num_layers=2, batch_first=True)\n",
    "\n",
    "        # Categorical feature embeddings\n",
    "        self.gene_embedding = nn.Embedding(gene_size, gene_emb_dim)\n",
    "        self.variance_embedding = nn.Embedding(variance_size, variance_emb_dim)\n",
    "        # Fully connected layer for classification\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim + gene_emb_dim + variance_emb_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, text_input, gene_input, variannce_input):\n",
    "        # Process text input through embedding and LSTM\n",
    "        text_embedded = self.text_embedding(text_input)\n",
    "        lstm_out, _ = self.lstm(text_embedded)\n",
    "        lstm_out = lstm_out[:, -1, :]  # Take the last hidden state\n",
    "\n",
    "        # Process categorical inputs through embeddings\n",
    "        gene_embedded = self.gene_embedding(gene_input).squeeze(1)\n",
    "        variance_embedded = self.variance_embedding(variannce_input).squeeze(1)\n",
    "\n",
    "        # Concatenate all features\n",
    "        combined = torch.cat((lstm_out, gene_embedded, variance_embedded), dim=1)\n",
    "\n",
    "        # Classification output\n",
    "        output = self.fc(combined)\n",
    "        return output\n",
    "\n",
    "\n",
    "# Model Initialization\n",
    "model = MultiClassLSTM(vocab_size, embed_dim, hidden_dim, num_classes, gene_size, variance_size, gene_emb_dim, variance_emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.memory_allocated())\n",
    "print(torch.cuda.max_memory_allocated())\n",
    "\n",
    "import gc\n",
    "# del train_data, test_data, val_data  # Delete variables if they exist\n",
    "gc.collect()  # Python garbage collection\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_full_np = np.concatenate([y_train, y_test, y_val])  # Full dataset labels\n",
    "unique_classes = np.unique(y_full_np)\n",
    "\n",
    "# unique_classes = torch.tensor(y_train_tensor)\n",
    "class_weights = compute_class_weight(class_weight=\"balanced\", classes=unique_classes.cpu().numpy(), y=y_full_np)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32, device=device)\n",
    "\n",
    "# Define loss function with class weights\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "  def __init__(self,text,gene,variance,classes):\n",
    "    self.text = text\n",
    "    self.gene = gene\n",
    "    self.variance = variance\n",
    "    self.classes = classes\n",
    "    self.device = device\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.text.shape[0]\n",
    "\n",
    "  def __getitem__(self,idx):\n",
    "    return self.text[idx], self.gene[idx], self.variance[idx], self.classes[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(text_to_numerical_representation_train,gene_train_encoded,variation_train_encoded,y_train)\n",
    "test_dataset = CustomDataset(text_to_numerical_representation_test,gene_test_encoded,variation_test_encoded,y_test)\n",
    "val_dataset = CustomDataset(text_to_numerical_representation_val,gene_val_encoded,variation_val_encoded,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset,batch_size=8,shuffle=True,)\n",
    "test_dataloader = DataLoader(test_dataset,batch_size=8,shuffle=True)\n",
    "validation_dataloader = DataLoader(val_dataset,batch_size=8,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !set CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "# The flag below controls whether to allow TF32 on cuDNN. This flag defaults to True.\n",
    "torch.backends.cudnn.allow_tf32 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_epochs = 10\n",
    "# train_losses = []\n",
    "# val_losses = []\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()  # Set model to training mode\n",
    "#     total_train_loss = 0\n",
    "\n",
    "#     for batch in train_dataloader:\n",
    "#         text_input, gene_input, variance_input, labels = batch\n",
    "\n",
    "#         # Move to device (if using GPU)\n",
    "#         # text_input = text_input.to(device)\n",
    "#         print(type(text_input))\n",
    "#         # # gene_input = gene_input.to(device)\n",
    "#         # print(type(gene_input))\n",
    "#         # # variance_input = variance_input.to(device)\n",
    "#         # print(type(variance_input))\n",
    "#         # # labels = labels.to(device)  # Labels should be integer class indices\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "model.to(device)\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    total_train_loss = 0\n",
    "\n",
    "    for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs} [Training]\"):\n",
    "        text_input, gene_input, variance_input, labels = batch\n",
    "\n",
    "        # Move to device (if using GPU)\n",
    "        text_input = text_input.to(device)\n",
    "        gene_input = gene_input.to(device)\n",
    "        variance_input = variance_input.to(device)\n",
    "        labels = labels.to(device)  # Labels should be integer class indices\n",
    "\n",
    "        # print(text_input.device, gene_input.device, variance_input.device, labels.device)\n",
    "\n",
    "        optimizer.zero_grad()  # Clear previous gradients\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(text_input, gene_input, variance_input)\n",
    "\n",
    "        # Compute Log Loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "    # Compute average training loss\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # ================== Validation Phase ==================\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    total_val_loss = 0\n",
    "\n",
    "    with torch.no_grad():  # No gradient calculation during validation\n",
    "        for batch in tqdm(validation_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs} [Validation]\"):\n",
    "            text_input, gene_input, variance_input, labels = batch\n",
    "            text_input = text_input.to(device)\n",
    "            gene_input = gene_input.to(device)\n",
    "            variance_input = variance_input.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(text_input, gene_input, variance_input)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(validation_dataloader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "# Store losses for future use\n",
    "torch.save({'train_loss': train_losses, 'val_loss': val_losses}, 'losses.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Q1. what is num_embeddings?\n",
    "- Q2. what is squeeze?\n",
    "- Q3. what is text_embedded.mean(dim=1)?\n",
    "- Q4. what is hidden_dim in LSTM as well as sequentiial?\n",
    "- Q5 why doing this lstm_out[:, -1, :]?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()  # Collect garbage\n",
    "torch.cuda.empty_cache()  # Free GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(text_data, \"preprocessed_text.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(y_train) + set(y_test) + set(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
